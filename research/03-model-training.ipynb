{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97b8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8ce6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ITI\\\\DS Track\\\\Deep Learning\\\\Projects\\\\Kidney Classification\\\\Kidney-Disease-Classification\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd92113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ITI\\\\DS Track\\\\Deep Learning\\\\Projects\\\\Kidney Classification\\\\Kidney-Disease-Classification'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d7fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcfc3276",
   "metadata": {},
   "source": [
    "## Workflows\n",
    "\n",
    "1. Update config.yaml\n",
    "2. Update secrets.yaml [Optional]\n",
    "3. Update params.yaml\n",
    "4. Update the entity\n",
    "5. Update the configuration manager in src config\n",
    "6. Update the components\n",
    "7. Update the pipeline \n",
    "8. Update the main.py\n",
    "9. Update the dvc.yaml\n",
    "10. app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366e54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6aeac19",
   "metadata": {},
   "source": [
    "# Update Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfbbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir:Path\n",
    "    trained_model_path:Path\n",
    "    updated_base_model:Path\n",
    "    training_data:Path\n",
    "    params_epochs:int\n",
    "    params_batch_size:int\n",
    "    params_is_augmented:bool\n",
    "    params_image_size:list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363ba09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8adff329",
   "metadata": {},
   "source": [
    "# Update ConfigManger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ed2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CNNClassifierKidneyDiseases.constants import *\n",
    "from src.CNNClassifierKidneyDiseases.utils.common import read_yaml , create_directories\n",
    "import torch\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import urllib.request as requests\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "import tqdm \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d415f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    # THOSE CONSTATN VARS, from src.constants \n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath =PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifact_root])\n",
    "\n",
    "    \n",
    "    def get_training_config(self)->TrainingConfig:\n",
    "\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir,\"kidney-ct-scan-image\")\n",
    "\n",
    "        create_directories([training.root_dir])\n",
    "\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "\n",
    "            root_dir=training.root_dir,\n",
    "            trained_model_path=Path(training.training_model_path),\n",
    "            updated_base_model=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmented=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "\n",
    "        )\n",
    "\n",
    "        return training_config\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863d249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d746ca26",
   "metadata": {},
   "source": [
    "# Updata Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e307f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "import urllib.request as requests\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module\n",
    "import torch.optim as optim\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "import tqdm \n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "363a0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "\n",
    "    def __init__(self,config:TrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = torch.load(self.config.updated_base_model,weights_only=False)\n",
    "        #self.model.eval()\n",
    "\n",
    "    def train_valid_loader(self):\n",
    "        image_size = self.config.params_image_size[1:]\n",
    "        means = [0.1921, 0.1921, 0.1921]\n",
    "        stds = [0.2601, 0.2601, 0.2601]\n",
    "\n",
    "        if self.config.params_is_augmented:\n",
    "            train_transform = transforms.Compose([\n",
    "\n",
    "                transforms.RandomResizedCrop(image_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(degrees=30),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = means , std = stds)\n",
    "            ])\n",
    "        else:\n",
    "            train_transform = transforms.Compose([\n",
    "\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=means , std=stds)\n",
    "            ])\n",
    "\n",
    "            valid_transforms = transforms.Compose([\n",
    "\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=means, std= stds)\n",
    "            ])\n",
    "\n",
    "        # full dataset\n",
    "\n",
    "        full_dataset = datasets.ImageFolder(self.config.training_data,transform=train_transform)\n",
    "        #self.train_dataset, self.val_dataset = random_split(full_dataset,[0.8 , 0.2], generator=g)\n",
    "        val_size = int(0.2 * len(full_dataset))\n",
    "        train_size = len(full_dataset) - val_size\n",
    "\n",
    "        # Splitting the train valid\n",
    "        self.train_dataset , self.valid_dataset = torch.utils.data.random_split(full_dataset,[train_size , val_size])\n",
    "\n",
    "\n",
    "        # Train loader And Valid loader\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_dataset , batch_size=self.config.params_batch_size , shuffle=True)\n",
    "\n",
    "        self.valid_loader = DataLoader(self.valid_dataset, batch_size=self.config.params_batch_size, shuffle=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path : Path , model: torch.nn.Module):\n",
    "        torch.save(model,path)\n",
    "\n",
    "    def train(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(device)\n",
    "        criteration = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters() , lr = 0.001)\n",
    "\n",
    "        for epoch in range(self.config.params_epochs):\n",
    "            self.model.train()\n",
    "            total_loss , correct , total = 0,0,0\n",
    "\n",
    "            for images , labels in self.train_loader:\n",
    "                images , labels = images.to(device) , labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self.model(images)\n",
    "                loss = criteration(y_pred , labels)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, preds = torch.max(y_pred,1)\n",
    "                correct += (preds ==labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        train_accuracy = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{self.config.params_epochs}, \"\n",
    "                f\"Loss: {total_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "        \n",
    "\n",
    "        # Validation\n",
    "        self.model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        self.save_model(path=self.config.trained_model_path, model=self.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CNNClassifierKidneyDiseases import logger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "\n",
    "class Training:\n",
    "\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = torch.load(self.config.updated_base_model, weights_only=False)\n",
    "\n",
    "    def train_valid_loader(self):\n",
    "        image_size = self.config.params_image_size[1:]\n",
    "        means = [0.1921, 0.1921, 0.1921]\n",
    "        stds = [0.2601, 0.2601, 0.2601]\n",
    "\n",
    "        if self.config.params_is_augmented:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(image_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(degrees=30),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=means, std=stds)\n",
    "            ])\n",
    "        else:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=means, std=stds)\n",
    "            ])\n",
    "\n",
    "        valid_transforms = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=means, std=stds)\n",
    "        ])\n",
    "\n",
    "        full_dataset = datasets.ImageFolder(self.config.training_data, transform=train_transform)\n",
    "        val_size = int(0.2 * len(full_dataset))\n",
    "        train_size = len(full_dataset) - val_size\n",
    "\n",
    "        self.train_dataset, self.valid_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.config.params_batch_size, shuffle=True)\n",
    "        self.valid_loader = DataLoader(self.valid_dataset, batch_size=self.config.params_batch_size, shuffle=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: torch.nn.Module):\n",
    "        torch.save(model, path)\n",
    "\n",
    "    def train(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "        logger.info(f\"Training started on device: {device}\")\n",
    "\n",
    "        for epoch in range(self.config.params_epochs):\n",
    "            self.model.train()\n",
    "            total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = self.model(images)\n",
    "                loss = criterion(y_pred, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                _, preds = torch.max(y_pred, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Log loss for each batch\n",
    "                \"\"\"logger.info(f\"Epoch [{epoch+1}/{self.config.params_epochs}] - \"\n",
    "                            f\"Batch [{batch_idx+1}/{len(self.train_loader)}] - \"\n",
    "                            f\"Batch Loss: {loss.item():.4f}\") \"\"\"\n",
    "\n",
    "            train_accuracy = correct / total\n",
    "            logger.info(f\"Epoch [{epoch+1}/{self.config.params_epochs}] - \"\n",
    "                        f\"Total Loss: {total_loss:.4f} - Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        self.model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        logger.info(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        self.save_model(path=self.config.trained_model_path, model=self.model)\n",
    "        logger.info(f\"Model saved to: {self.config.trained_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb9c2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-06 13:57:16,138: INFO: common: yaml file config\\config.yaml loaded successfully]\n",
      "[2025-07-06 13:57:16,139: INFO: common: yaml file params.yaml loaded successfully]\n",
      "[2025-07-06 13:57:16,141: INFO: common: Created Directory at : artifacts]\n",
      "[2025-07-06 13:57:16,142: INFO: common: Created Directory at : artifacts/training]\n",
      "[2025-07-06 13:57:16,385: INFO: 1776341136: Training started on device: cpu]\n",
      "[2025-07-06 13:57:59,874: INFO: 1776341136: Epoch [1/10] - Total Loss: 6.9926 - Accuracy: 0.6774]\n",
      "[2025-07-06 13:58:43,771: INFO: 1776341136: Epoch [2/10] - Total Loss: 5.5876 - Accuracy: 0.7823]\n",
      "[2025-07-06 13:59:27,443: INFO: 1776341136: Epoch [3/10] - Total Loss: 4.2378 - Accuracy: 0.8602]\n",
      "[2025-07-06 14:00:11,054: INFO: 1776341136: Epoch [4/10] - Total Loss: 3.8049 - Accuracy: 0.8844]\n",
      "[2025-07-06 14:00:56,978: INFO: 1776341136: Epoch [5/10] - Total Loss: 3.3717 - Accuracy: 0.8898]\n",
      "[2025-07-06 14:01:42,230: INFO: 1776341136: Epoch [6/10] - Total Loss: 3.8698 - Accuracy: 0.8737]\n",
      "[2025-07-06 14:02:37,094: INFO: 1776341136: Epoch [7/10] - Total Loss: 3.6747 - Accuracy: 0.8763]\n",
      "[2025-07-06 14:03:32,835: INFO: 1776341136: Epoch [8/10] - Total Loss: 4.0202 - Accuracy: 0.8522]\n",
      "[2025-07-06 14:04:27,634: INFO: 1776341136: Epoch [9/10] - Total Loss: 3.4889 - Accuracy: 0.8629]\n",
      "[2025-07-06 14:05:22,702: INFO: 1776341136: Epoch [10/10] - Total Loss: 3.9614 - Accuracy: 0.8575]\n",
      "[2025-07-06 14:05:35,720: INFO: 1776341136: Validation Accuracy: 0.9462]\n",
      "[2025-07-06 14:05:36,548: INFO: 1776341136: Model saved to: artifacts\\training\\model.pth]\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_loader()\n",
    "    training.train()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KidneyClassification",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
